
%
% Stel je wilt het C++-programma iets.cc mooi printen,
% en wellicht er nog wat begeleidende tekst bij schrijven.
%

\documentclass{article}

\setlength{\textheight}{25.7cm}
\setlength{\textwidth}{16cm}
\setlength{\unitlength}{1mm}
\setlength{\topskip}{2.5truecm}
\topmargin 260mm \advance \topmargin -\textheight 
\divide \topmargin by 2 \advance \topmargin -1in 
\headheight 0pt \headsep 0pt \leftmargin 210mm \advance
\leftmargin -\textwidth 
\divide \leftmargin by 2 \advance \leftmargin -1in 
\oddsidemargin \leftmargin \evensidemargin \leftmargin
\parindent=12pt

\frenchspacing
\newcommand{\SA}{Simulated Annealing }

\usepackage[english]{babel}
\usepackage{amsmath}

\usepackage{listings}
% Er zijn talloze parameters ...
\lstset{language=C++, showstringspaces=false, basicstyle=\small,
  numbers=left, numberstyle=\tiny, numberfirstline=false,
  stepnumber=1, tabsize=4, 
  commentstyle=\ttfamily, identifierstyle=\ttfamily,
  stringstyle=\itshape}

\title{Neural Networks: Assignment 1}
\author{Pepijn van Heiningen \& Michiel Vos}

\begin{document}

\maketitle

\section{Introduction}
For the first assignment of the Neural Networks course there were two tasks:
\begin{itemize}
\item Parameter Estimation
\item Classification of handwritten digits
\end{itemize}

\subsection{Task 1}
The first task consists of $3$ different parts. For the first part we were given four samples and four density functions. The task was to find the most likely density function that was used to generate a sample. 
The second part asked to demonstrate that the area under the parabolic density function was always equal to $1$, indepentendly on the value of the input parameter \verb+s+.
Finally we were given a dataset which corresponded to a Gaussian mixture of two normal distributions. The assignment was to find the correct values for the parameters using three different methods.

\subsection{Task 2}

\section{Task 1: Parameter Estimation}
\subsection{Problem Description}
We were given 4 datasets (A, B, C and D) and 4 density functions (Normal, Parabolic, Triangular and Rectangular). The task was to find out what dataset was most likely generated by a particular density function. 

Subsequently we had to demonstrate that the area under the parabola was always $1$.

Finally we were given another dataset, a Gaussian mixture of two normal distributions. We were asked to estimate the six different parameters ($p_A, p_B, \mu_A, \mu_B, \sigma_A, \sigma_B$) using three different methods:

\begin{itemize}
\item By directly calulating the values of the parameters.
\item By trying to brute-force the correct values.
\item By using the Expectation Maximization algorithm.
\end{itemize} 

\subsection{Problem Solution}
To solve the first part of task $1$, we wrote a function that estimated the log likelihood that a sample came from a given distribution. We applied it to all four samples, ranging the parameter \verb+s+ between $0,5$ and $1,5$ with a stepsize of $0,001$, to find the most likely distribution type. In table \ref{table:data1} you can find the results. \\

\begin{table}[!h]
	\begin{center}
		\begin{tabular}{l|l|l}
			Dataset & Density function & \verb+s+ \\
			\hline
			\verb+A+ & Parabolic   & 0,79  \\
			\verb+B+ & Normal  & 0,54 \\
			\verb+C+ & Rectangular   & 1,09   \\
			\verb+D+ & Triangular   & 0,99   \\
		\end{tabular}
		\caption{Datasets and most likely density functions}
		\label{table:data1}
	\end{center}
\end{table}

To demonstrate that the area under the parabolic density function was always $1$, we calculated the area under the curve for input values of \verb+s+ between $0,01$ and $100$ with a stepsize of $0,01$. By showing that the mean of these values is $1$ and the standard deviation $0$, we know that all output values were equal to $1$.

First we directly calculated the six parameters by using the class variable. The outcome is in table \ref{table:data2}. \\\\

\begin{table}[!h]
	\begin{center}
		\begin{tabular}{l|l|l|l|l|l}
			$p_A$ & $p_B$ & $\mu_A$ & $\mu_B$ & $\sigma_A$ & $\sigma_B$ \\
			\hline
			0,63 & 0,37 & 46,81 & 63,63 & 3,67 & 1,18 \\
		\end{tabular}
		\caption{Calculated parameters and their values}
		\label{table:data2}
	\end{center}
\end{table}

Subsequently we tried the brute-force technique to find the optimal values. The number of combinations was: $2,25 \cdot 10^{11}$. In total it would take $5,77 \cdot 10^6$ seconds or approximately $66,8$ days to brute-force on an Intel Core $i5$-$3470$.\\\\

Finally we used the EM-algorithm to find the optimal values of the mixture parameters. (See table \ref{table:data3}) First we initialized the Gaussian mixture model by using the k-means algorithm for $10$ iterations. Then we trained it using the given dataset for another $10$ generations. Training the model for $10$ iterations took  $0.004762$ seconds, so this approach is approximately $4.7 \cdot 10^{13}$ times faster than the brute-force approach. If we compare the values found with the ``true'' model, we see that there are no differences to $2$ decimals behind the comma. 

\begin{table}[!h]
	\begin{center}
		\begin{tabular}{l|l|l|l|l|l}
			$p_A$ & $p_B$ & $\mu_A$ & $\mu_B$ & $\sigma_A$ & $\sigma_B$ \\
			\hline
			0,63 & 0,37 & 46,81 & 63,63 & 3,67 & 1,18 \\
		\end{tabular}
		\caption{Approximated parameters and their values}
		\label{table:data3}
	\end{center}
\end{table}


\section{Task 2: ClassiÔ¨Åcation of handwritten digits}
\subsection{Problem Description}


\subsection{Problem Solution}



\end{document}
